<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>modification minimap2</title>

		<link rel="stylesheet" href="../slides_common/css/reveal.css">
		<link rel="stylesheet" href="../slides_common/css/theme/white.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../slides_common/css/print/pdf.css' : '../slides_common/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
		<style>
			.reveal .slide-number { font-size: 15px; }
			.reveal .progress { height: px; }
			.reveal .baseline, .reveal .baseline * { vertical-align: baseline; }
			.reveal .noupper { text-transform: none; }

			object { width: 100%; }
			.twothird { width: 66%; }
			.reveal pre.cmd { 
				position: absolute; 
				top: 2.5em; right: 0;  
				font-size: 50%;
				width:auto; 
				padding: 0.25em; 
			}
			.reveal section img {
				border: none;
			}
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h2>Parallel decompression of</h2>
					<h1>gzip files</h1>
					<p>
						<small>Maël Kerbiriou @ BONSAI<br/>Lille, France</small>
					</p>
				</section>

				<section>
						<h2>GZIP</h2>
						<h3>History at a glance</h3>
						<p><pre>gzip</pre> is an utility and file format for lossless compression using the LZ77 and Huffman coding</p>
						<ul>
							<li>LZ77 <small>(Abraham Lempel and Jacob Ziv, 1977)</small> allows is used repetitions in the stream</li>
							<li>Huffman coding (1952) assign a code of optimal length for each symbol</li>
							<li>the DEFLATE algorithm, first used in <code>PKZIP</code> in 1989, combines the two</li>
							<li>gzip 0.1, released on 1992, is the GNU implementation of DEFLATEwith it's own file container format</li>
						</ul>
				</section>

				<section>
					<h3>gzip usage in bioinformatics</h3>
					<ul>
						<li>Text file format are frequent in  bioinformatics</li>
						<li>gzip is a natural choice for generic compression o f text file:
							<ul>
								<li>ASCII only: immediate 7/8bits space reduction</li>
								<li>FASTA: 4 symbols, short repetitions in DNA</li>
								<li>VCF,BED,...: digits/sperators, repeated fields</li>
							</ul>
						</li>
						<li>gzip is ubiquitous and fast <small>(Especially at compression level <code>-0</code>)</small></li>
						<li>However, it is not best in class in either compression/decompression nor compression ratio<br/>
						<small>See <i>eg.</i> brotli or Zstd <a href="https://quixdb.github.io/squash-benchmark">https://quixdb.github.io/squash-benchmark</a></small></li>
					</ul>	
				</section>


				<section>
					<h3>gzip usage in bio-informatics</h3>
					<ul>
						<li>Sequencing throughput is increassing at a exponential rate</li>
						<li>Storage of raw reads data, while being a hassle, is a necessity for reproductible science and enabling re-analysis.</li>
						<li>Most labs use the Illumina tool <code>bcl2fastq2</code> which compress to gzip</li>
						<li>Again, even if better specialized format for SR exists, gzip is ubiquitous and "good enough"<br/>
						⇒<code>.fq.gz</code> format is here to stay, at least as an interchange format.</li>

					</ul>
				</section>

				<section>
						<h2>Parallelism</h2>
						<h3>Why is it desirable ?</h3>
						<ul>
							<li>Moore's law is dead, clock frequencies and IPC are stagnating</li>
							<li>The way-out is multi-core parallelism</li>
							<li>>4 cores CPUs are common in servers and developping in the consumer market.</li>
						</ul>
				</section>

				<section>
					<h2>Parallel decompression</h2>
					<h3>Why is it desirable ?</h3>
					<ul>
						<li>Some routine data processing <small>(read/kmer counting, quality averaging)</small> are not intrinsicly CPU-heavy tasks</li>
						<li>Most of CPU time is spent on decompressing gzip files</li>
						<li>If not, the compute task could be parallelized, and decompression would become the bottleneck again</li>
						<li>IO bottlenecks are not a problem with the current generation of NAS and NVMe drives</li>
					</ul>
				</section>

				<section>
					<h2>The problems with gzip</h2>
					<h3>LZ77 sliding window</h3>
					<ul>
						<li>LZ77 encode the stream with two kind of symbols<ul>
							<li>Literals: a character from the original stream</li>
							<li>Matches: a substream of the past stream</li>
						</ul></li>
						<li>Matches can reference the past 32KB of decoded data: this is the sliding window</li>
						<li>The window is never reset: through transitivity, the end of the stream might reference some characters at the begining</li>
						<li><b>We cannot seek in the stream if we don't know the previous 32KB</b></li>
					</ul>
				</section>


				<section>
					<h2>The problems with gzip</h2>
					<h3>Adaptative Huffman code</h3>
					<ul>
						<li>The deflate stream is segmented into blocks, each with a different huffman tree</li>
						<li>The block delimitation is signaled with in band coding: no length field in block headers</li>
						<li>A prefix code streams is not byte aligned, nor are the block limits</li>
					</ul>
				</section>

				<section>
						<h3>Syncing to the start of a block</h3>
						<p>Brute force approach: try every bit position until one yield an acceptable result</p>
						<p>Rewind and try next bit position in case of: <p>
						<ul>
							<li>Block header or Huffman tree invariant check fails</li>
							<li>Unknown Huffman symbol</li>
							<li>Non ASCII litteral</li>
						</ul>
				</section>

				<section>
						<h3>Decompressing with an unknown context</h3>
						<p>First approach: fill the windows with dummy character and advance the de coding untill none remains.</p>
						<ul>
							<ul>Geometric decay of the number of unknown symbols</ul>
							<ul>with a treshold effect: few frequently used symbols (such a newlines) remains until the end of the stream</ul>
							<ul>Perspective: use FASTQ specifics heuristics to extract sequence even in the presence of unknown symbols (<code>fqgz</code>)</code></ul>
						</ul>
				</section>

				<section>
						<h3>Decompressing with an unknown context</h3>
						<p>Second approach: fill the windows with unique symbols, do a second pass substitiuting those symbols with the context once it is known (<code>pugz</code>)</p>
				</section>

				<section>
						<h3>Optimizations &#38; Implementation details</h3>
						<ul>
							<li>The two pass method implies to conserve the whole chunks into memory</li>
							<li>With geometric decay, the 32K symbols quicly decay to 127 symbols allowing to store them as char along with ASCII litterals</li>
						</ul>
				</section>

				<section>
						<h3>Performance</h3>
				</section>


				<section>
						<h3>Conclusion</h3>
				</section>


		
			</div>
		</div>

		<script src="../slides_common/lib/js/head.min.js"></script>
		<script src="../slides_common/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				history: true,
				controls: false,
				math: {
					mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
					config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
				},
				dependencies: [
					{ src: '../slides_common/plugin/math/math.js', async: true },
					{ src: '../slides_common/plugin/notes/notes.js', async: true },
					
				]
			});
			Reveal.configure({ slideNumber: 'c/t' });
		</script>
	</body>
</html>
